{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df805d26-5195-4c5b-9ebe-dcbb600b9216",
   "metadata": {},
   "source": [
    "# Tutorial SPacy\n",
    "Link al curso -> [NLP avanzado con spaCy](https://course.spacy.io/es/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0488c23d-f16c-4fdf-b5e9-4d2a1053b76e",
   "metadata": {},
   "source": [
    "# Capitulo 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6d5cf8-5c99-4500-ba2d-a91ead3ebc4a",
   "metadata": {},
   "source": [
    "## Introducción a spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b55d9a15-4fe4-477b-9e6e-86bf99760073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa la clase de lenguaje \"Spanish\"\n",
    "from spacy.lang.es import Spanish\n",
    "\n",
    "# Crea el objeto nlp\n",
    "nlp =  Spanish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93f84236-0c75-4439-b4c2-66bddc9f4e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡\n",
      "Hola\n",
      "Mundo\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Creado procesado un string de texto con nlp\n",
    "doc = nlp(\"¡Hola Mundo!\")\n",
    "\n",
    "# Itera sobre los tokens de doc\n",
    "for token in doc:\n",
    "    print(token.text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61c927f9-a560-4ed8-8c29-e44fc94e614c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'spacy.tokens.token.Token'>\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "print(type(doc[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8211be89-4373-45c2-b88c-aa44cc93ec51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:  [0, 1, 2, 3, 4]\n",
      "Text:  ['Eso', 'cuesta', '€', '5', '.']\n",
      "is_alpha:  [True, True, False, False, False]\n",
      "is_punct:  [False, False, False, False, True]\n",
      "like_num:  [False, False, False, True, False]\n"
     ]
    }
   ],
   "source": [
    "doc2 = nlp(\"Eso cuesta €5.\")\n",
    "# Atributos de los tokenes\n",
    "print(\"Index: \", [token.i for token in doc2])\n",
    "print(\"Text: \", [token.text for token in doc2])\n",
    "\n",
    "print(\"is_alpha: \", [token.is_alpha for token in doc2])\n",
    "print(\"is_punct: \", [token.is_punct for token in doc2])\n",
    "print(\"like_num: \", [token.like_num for token in doc2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a04ddc7-85b0-437e-a8bf-717182359a2d",
   "metadata": {},
   "source": [
    "## Modelos Estadísticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f561ed21-e9a1-48fe-a9a5-0a057d887068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ella PRON nsubj comió\n",
      "comió VERB ROOT comió\n",
      "pizza NOUN obj comió\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Carga el modelo pequeño de español\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "# Procesa un texto\n",
    "doc = nlp(\"Ella comió pizza\")\n",
    "\n",
    "# Itera sobre los tokens\n",
    "for token in doc:\n",
    "    # Imprime en pantalla el texto y el part-of-speech tag prediction\n",
    "    print(token.text, token.pos_, token.dep_, token.head.text)\n",
    "    # Imprime \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "733afdc1-fe4a-48b8-83d4-a73f69f232c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple ORG\n",
      "EE.UU. LOC\n",
      "iPhone MISC\n",
      "Galaxy Note MISC\n"
     ]
    }
   ],
   "source": [
    "# Procesa un texto\n",
    "doc = nlp(\n",
    "    \"Apple es la marca que más satisfacción genera en EE.UU., \"\n",
    "    \"pero el iPhone, fue supera por el Galaxy Note 9\"\n",
    ")\n",
    "\n",
    "# Itera sobre las entidades predichas\n",
    "for ent in doc.ents:\n",
    "    # Imprime en pantalla el texto y el label de la entidad\n",
    "    print(ent.text, ent.label_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69186e16-b21f-439d-9298-70deabeeb14a",
   "metadata": {},
   "source": [
    "Obtén definiciones rápidas de los tags y labels más comunes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae9a22a1-b1e7-491c-a74a-e54803b10330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-GPE locations, mountain ranges, bodies of water\n",
      "--------------------\n",
      "noun, proper singular\n",
      "--------------------\n",
      "Miscellaneous entities, e.g. events, nationalities, products or works of art\n"
     ]
    }
   ],
   "source": [
    "print(spacy.explain(\"LOC\"))\n",
    "print(\"-\"*20)\n",
    "print(spacy.explain(\"NNP\"))\n",
    "print(\"-\"*20)\n",
    "print(spacy.explain(\"MISC\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a957642c-ad3d-4b76-aee3-1ec6d22e94f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "De          ADP       case      \n",
      "acuerdo     NOUN      fixed     \n",
      "con         ADP       fixed     \n",
      "la          DET       det       \n",
      "revista     NOUN      obl       \n",
      "Fortune     PROPN     appos     \n",
      ",           PUNCT     punct     \n",
      "Apple       PROPN     nsubj     \n",
      "fue         AUX       cop       \n",
      "la          DET       det       \n",
      "empresa     NOUN      ROOT      \n",
      "más         ADV       advmod    \n",
      "admirada    ADJ       amod      \n",
      "en          ADP       case      \n",
      "el          DET       det       \n",
      "mundo       NOUN      obl       \n",
      "entre       ADP       case      \n",
      "2008        NOUN      obl       \n",
      "y           CCONJ     cc        \n",
      "2012        NOUN      conj      \n",
      ".           PUNCT     punct     \n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "text = (\n",
    "    \"De acuerdo con la revista Fortune, Apple fue la empresa \"\n",
    "    \"más admirada en el mundo entre 2008 y 2012.\"\n",
    ")\n",
    "\n",
    "# Procesa el texto\n",
    "doc = nlp(text)\n",
    "\n",
    "for token in doc:\n",
    "    # Obtén el texto del token, el part-of-speech tag y el dependency label\n",
    "    token_text = token.text\n",
    "    token_pos = token.pos_\n",
    "    token_dep = token.dep_\n",
    "    # Esto es solo por formato\n",
    "    print(\"{:<12}{:<10}{:<10}\".format(token_text, token_pos, token_dep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d72f3a9-bd0b-414a-8c53-87299f1a7ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "revista Fortune ORG\n",
      "Apple ORG\n"
     ]
    }
   ],
   "source": [
    "# Itera sobre las entidades predichas\n",
    "for ent in doc.ents:\n",
    "    # Imprime en pantalla el texto de la entidad y su label\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "277c5e53-58d7-411f-9610-1ec57d946d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Olímpicos LOC\n",
      "Tokio LOC\n",
      "Entidad faltante: adidas zx\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "text = (\n",
    "    \"Los Olímpicos de Tokio 2020 son la inspiración para la nueva \"\n",
    "    \"colección de zapatillas adidas zx.\"\n",
    ")\n",
    "\n",
    "# Procesa el texto\n",
    "doc = nlp(text)\n",
    "\n",
    "# Itera sobre las entidades\n",
    "for ent in doc.ents:\n",
    "    # Imprime en pantalla el texto de la entidad y su label\n",
    "    print(ent.text, ent.label_)\n",
    "\n",
    "# Obtén el span para \"adidas zx\"\n",
    "adidas_zx = doc[-3:-1]\n",
    "\n",
    "# Imprime en pantalla el texto del span\n",
    "print(\"Entidad faltante:\", adidas_zx.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c2f70e-7fbe-4d2f-859e-be199c76068d",
   "metadata": {},
   "source": [
    "## Encontrando patrones basados en reglas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3be991fa-3334-4459-9cc1-b6613d9ce324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(12542628451813468933, 7, 9)]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Importa el Matcher\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "# Inicializa el matcher con el vocubalorio compartido\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Añade el patrón al matcher\n",
    "pattern = [{\"TEXT\": \"adidas\"}, {\"TEXT\": \"zx\"}]\n",
    "matcher.add(\"ADIDAS PATTERN\", [pattern])\n",
    "\n",
    "# Procesa un texto\n",
    "doc = nlp(\"Nuevos diseños de zapatillas en la colección adidas zx\")\n",
    "\n",
    "# Llama al matcher sobre el doc\n",
    "matches = matcher(doc)\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d586c117-8871-4bbd-8a51-714b3f08845d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adidas zx\n"
     ]
    }
   ],
   "source": [
    "# Itera sobre los resultados\n",
    "for matched_id, start, end in matches:\n",
    "    # Obtén el span resultante\n",
    "    matcher_span = doc[start:end]\n",
    "    print(matcher_span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "23bc65f9-0850-43d8-b8d4-17e08f75be00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(12634997056414607316, 0, 5)]\n",
      "2014 Copa Mundial FIFA:\n"
     ]
    }
   ],
   "source": [
    "pattern = [\n",
    "    {\"IS_DIGIT\": True},\n",
    "    {\"LOWER\": \"copa\"},\n",
    "    {\"LOWER\": \"mundial\"},\n",
    "    {\"LOWER\": \"fifa\"},\n",
    "    {\"IS_PUNCT\": True}\n",
    "]\n",
    "doc = nlp(\"2014 Copa Mundial FIFA: Alemania ganó!\")\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add(\"FIFA PATTERN\", [pattern])\n",
    "matches = matcher(doc)\n",
    "print(matches)\n",
    "\n",
    "for matched_id, start, end in matches:\n",
    "    # Obtén el span resultante\n",
    "    matcher_span = doc[start:end]\n",
    "    print(matcher_span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e44db16d-27b4-4146-81e5-603d1f199ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = [\n",
    "    {\"LEMMA\": \"comer\", \"POS\": \"VERB\"},\n",
    "    {\"POS\": \"NOUN\"}\n",
    "]\n",
    "doc = nlp(\"Camila prefería comer tacos. Pero ahora está comiendo pasta.\")\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add(\"COMER PATTERN\", [pattern])\n",
    "matches = matcher(doc)\n",
    "\n",
    "\n",
    "for matched_id, start, end in matches:\n",
    "    # Obtén el span resultante\n",
    "    matcher_span = doc[start:end]\n",
    "    print(matcher_span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4e0c7bf0-d07c-4830-a5fc-bb1d651127ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compré un smartphone\n",
      "comprando aplicaciones\n"
     ]
    }
   ],
   "source": [
    "pattern = [\n",
    "    {\"LEMMA\": \"comprar\"},\n",
    "    {\"POS\": \"DET\", \"OP\":\"?\"}, # opcional: encuentra 0 o 1 veces\n",
    "    {\"POS\": \"NOUN\"}\n",
    "]\n",
    "doc = nlp(\"Me compré un smartphone. Ahora le estoy comprando aplicaciones.\")\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add(\"COMPRAR PATTERN\", [pattern])\n",
    "matches = matcher(doc)\n",
    "\n",
    "for matched_id, start, end in matches:\n",
    "    # Obtén el span resultante\n",
    "    matcher_span = doc[start:end]\n",
    "    print(matcher_span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538fdbd0-a9cb-42e3-bd8e-e478b9c953ca",
   "metadata": {},
   "source": [
    "{\"OP\": \"!\"}    Negación: encuentra 0 veces\n",
    "\n",
    "{\"OP\": \"?\"}    Opcional: encuentra 0 o 1 veces\n",
    "\n",
    "{\"OP\": \"+\"}    Encuentra: 1 o más veces\n",
    "\n",
    "{\"OP\": \"*\"}    Encuentra 0 o más veces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee08e39-0a1f-4ea4-8e2f-dfb3aaeb6aa0",
   "metadata": {},
   "source": [
    "## Escribiendo patrones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02778af8-d89e-4916-93bf-1dfa6e8eab62",
   "metadata": {},
   "source": [
    "Escribe un patrón que únicamente encuentre menciones de las versiones enteras de iOS: “iOS 7”, “iOS 11” and “iOS 10”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de00e2c6-863b-4427-a24d-1ecc1ae9a913",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "doc = nlp(\n",
    "    \"Después de hacer la actualización de iOS no notarás un rediseño \"\n",
    "    \"radical del sistema: no se compara con los cambios estéticos que \"\n",
    "    \"tuvimos con el iOS 7. La mayoría de las funcionalidades del iOS 11 \"\n",
    "    \"siguen iguales en el iOS 10.\"\n",
    ")\n",
    "\n",
    "# Escribe un patrón para las versiones de iOS enteras\n",
    "# (\"iOS 7\", \"iOS 11\", \"iOS 10\")\n",
    "pattern = [{\"TEXT\": \"iOS\"}, {\"IS_DIGIT\": True}]\n",
    "\n",
    "# Añade el patrón al matcher y usa el matcher sobre el documento\n",
    "matcher.add(\"IOS_VERSION_PATTERN\", None, pattern)\n",
    "matches = matcher(doc)\n",
    "print(\"Total matches found:\", len(matches))\n",
    "\n",
    "# Itera sobre los resultados e imprime el texto del span\n",
    "for match_id, start, end in matches:\n",
    "    print(\"Match found:\", doc[start:end].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e59094c-347f-4354-907d-ace700f85be3",
   "metadata": {},
   "source": [
    "Escribe un patrón que únicamente encuentre formas de “descargar” (tokens con el lemma “descargar”) seguido por un token que tenga el part-of-speech tag \"PROPN\" (proper noun)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84195ab-3bf8-4a45-8fc6-7bc2d1223785",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
